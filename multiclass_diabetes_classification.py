# -*- coding: utf-8 -*-
"""Multiclass Diabetes Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uxkk_1-c1UuUadc4W31_J0d0RAi5vHWw
"""

cd Downloads\Capstone

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import cross_val_score
dataSet = pd.read_csv('diabetestype.csv')
newDataset=dataSet

dataSet

print("How many Zero value are here: ")
print(dataSet.iloc[:, 0 : 7].eq(0).sum())

dataSet.dtypes

diabetes_true_count = len(dataSet.loc[dataSet['Class'] == True])
diabetes_false_count = len(dataSet.loc[dataSet['Class'] == False])

print("True Outcome: {0}, False Outcome: {1}".format(diabetes_true_count, diabetes_false_count))

dataSet.Type

lengthOfType=len(dataSet.Type)

print(dataSet.Type)

Outcome=[]
for i in dataSet.Type:
    if i=='Normal':
        Outcome.append(0)
    elif i=='Type1':
        Outcome.append(1)
    elif i=='Type2':
        Outcome.append(2)

len(Outcome)

dataSet['Outcomes']=Outcome

dataSet

dataSet=dataSet.drop('Class',axis=1)
dataSet=dataSet.drop('Type',axis=1)
dataSet

diabetes_Normal_count = len(dataSet.loc[dataSet['Outcomes'] == 0])
diabetes_Type1_count = len(dataSet.loc[dataSet['Outcomes'] == 1])
diabetes_Type2_count = len(dataSet.loc[dataSet['Outcomes'] == 2])

print("Normal Outcome: {0}, Type1 Outcome: {1}, Type2 Outcome: {2}".format(diabetes_Normal_count, diabetes_Type1_count, diabetes_Type2_count))

newDataSet=dataSet

dataSet.shape

print("How many Zero value are here: ")
print(dataSet.iloc[:, 0 : 7].eq(0).sum())

X = dataSet.iloc[:,:-1].values
y = dataSet.iloc[:,6].values

print(dataSet.isnull().sum())

dataSet.iloc[:,6].values

from sklearn.impute import SimpleImputer
fill_values = SimpleImputer(missing_values= 0, strategy = 'mean')
X[:,0:5] = fill_values.fit_transform(X[:,1:6])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)
from sklearn.preprocessing import StandardScaler
scale_X = StandardScaler()
X_train = scale_X.fit_transform(X_train)
X_test = scale_X.transform(X_test)

"""# SVM

"""

from sklearn.svm import SVC
SVM_classifier = SVC(kernel = 'rbf', gamma = 'auto', random_state = 0)
SVM_classifier.fit(X_train, y_train)
SVM_y_pred = SVM_classifier.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score
cm_SVM = confusion_matrix(y_test, SVM_y_pred)
ac_SVM = accuracy_score(y_test, SVM_y_pred)
print("Confusion Matrix :")
print(cm_SVM)
print("SVM Train/test Split Accurary: ", ac_SVM)

"""# KNN"""

#KNN Classifier Algorithm
from sklearn.neighbors import KNeighborsClassifier
KNNClassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)
KNNClassifier.fit(X_train, y_train)
KNN_y_pred = KNNClassifier.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score
cm_KNNclass = confusion_matrix(y_test, KNN_y_pred)
ac_KNNclass = accuracy_score(y_test,KNN_y_pred)
print("Confusion Matrix :")
print(cm_KNNclass)
print("KNN Train/test Split Accurary: ", ac_KNNclass)

"""# Decision Tree"""

#Decision Tree Classifier Algorithm
from sklearn.tree import DecisionTreeClassifier
DTreeClassifier = DecisionTreeClassifier(criterion="entropy", random_state=0)
DTreeClassifier.fit(X_train, y_train)

DTree_y_pred = DTreeClassifier.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score
cm_DTree = confusion_matrix(y_test, DTree_y_pred)
ac_DTree = accuracy_score(y_test, DTree_y_pred)
print("Decision Tree Train/test Split Confusion Matrix :")
print(cm_DTree)
print("Decision Tree Train/test Split Accurary: ", ac_DTree)

"""# Logisitic Regression"""

from sklearn.linear_model import LogisticRegression
LogisticClassifier = LogisticRegression(random_state = 0)
LogisticClassifier.fit(X_train, y_train)

log_y_pred = LogisticClassifier.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score
cm_log_reg = confusion_matrix(y_test, log_y_pred)
ac_log_reg = accuracy_score(y_test,log_y_pred)
print("Logistic Regression Train/test Split Confusion Matrix :")
print(cm_log_reg)
print("Logistic Regression Train/test Split Accurary: ", ac_log_reg)

"""# Naive-Bayes"""

from sklearn.naive_bayes import GaussianNB
NBclassifier = GaussianNB()
NBclassifier.fit(X_train, y_train)

NB_y_pred = NBclassifier.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score
cm_NBclass = confusion_matrix(y_test, NB_y_pred)
ac_NBclass = accuracy_score(y_test,NB_y_pred)
print("Naive-Bayes Train/Test Split Accuracy: ", ac_NBclass)
print("confusion matrix of Naive Bayes:",cm_NBclass)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
randomForestClassifier=RandomForestClassifier(n_estimators=100)
randomForestClassifier.fit(X_train,y_train)

randomForestClassifier.score(X_test,y_test)
rand_y_pred=randomForestClassifier.predict(X_test)
cm_randomForest= confusion_matrix(y_test,rand_y_pred)
ac_randomFores= accuracy_score(y_test,rand_y_pred)
print("Random Forest Classifier Accuracy:",ac_randomFores)
print("Random Forest Classifier Confusion Matrix",cm_randomForest)

"""# PreProcessing"""

newDataSet

newDataSet.rename({'BS Fast':'BS_Fast','BS pp':'BS_pp','Plasma R':'Plasma_R','Plasma F':'Plasma_F'},axis = 1, inplace = True)

age_mean=newDataSet.Age.mean()
age_std=newDataSet.Age.std()
print('Age_mean:',age_mean,end=" ")
print('Age_std:',age_std)
bs_Fast_mean=newDataSet.BS_Fast.mean()
bs_Fast_std=newDataSet.BS_Fast.std()
print('bs_Fast_mean:',bs_Fast_mean,end=" ")
print('bs_Fast_std:',bs_Fast_std)
bs_pp_mean=newDataSet.BS_pp.mean()
bs_pp_std=newDataSet.BS_pp.std()
print('bs_pp_mean:',bs_pp_mean,end=" ")
print('bs_pp_std:',bs_pp_std)
plasma_R_mean=newDataSet.Plasma_R.mean()
plasma_R_std=newDataSet.Plasma_R.std()
print('plasma_R_mean:',plasma_R_mean,end=" ")
print('plasma_R_std:',plasma_R_std)
plasma_F_mean=newDataSet.Plasma_F.mean()
plasma_F_std=newDataSet.Plasma_F.std()
print('plasma_F_mean:',plasma_F_mean,end=" ")
print('plasma_F_std:',plasma_F_std)
hba1c_mean=newDataSet.HbA1c.mean()
hba1c_std=newDataSet.HbA1c.std()
print('hba1c_mean:',hba1c_mean,end=" ")
print('hba1c_std:',hba1c_std)

upper=age_mean+(age_std*2)
lower=age_mean-(age_std*2)
newDataSet=newDataSet[(newDataSet.Age<upper) &(newDataSet.Age>lower)]
upper=bs_Fast_mean+(bs_Fast_std*2)
lower=bs_Fast_mean-(bs_Fast_std*2)
newDataSet=newDataSet[(newDataSet.BS_Fast<upper) &(newDataSet.BS_Fast>lower)]
upper=bs_pp_mean+(bs_pp_std*2)
lower=bs_pp_mean-(bs_pp_std*2)
newDataSet=newDataSet[(newDataSet.BS_pp<upper) &(newDataSet.BS_pp>lower)]
upper=plasma_F_mean+(plasma_F_std*2)
lower=plasma_F_mean-(plasma_F_std*2)
newDataSet=newDataSet[(newDataSet.Plasma_F<upper) &(newDataSet.Plasma_F>lower)]
upper=plasma_R_mean+(plasma_R_std*2)
lower=plasma_R_mean-(plasma_R_std*2)
newDataSet=newDataSet[(newDataSet.Plasma_R<upper) &(newDataSet.Plasma_R>lower)]
upper=hba1c_mean+(hba1c_std*2)
lower=hba1c_mean-(hba1c_std*2)
newDataSet=newDataSet[(newDataSet.HbA1c<upper) &(newDataSet.HbA1c>lower)]

newDataSet

diabetes_Normal_count = len(newDataSet.loc[newDataSet['Outcomes'] == 0])
diabetes_Type1_count = len(newDataSet.loc[newDataSet['Outcomes'] == 1])
diabetes_Type2_count = len(newDataSet.loc[newDataSet['Outcomes'] == 2])

print("Normal Outcome: {0}, Type1 Outcome: {1}, Type2 Outcome: {2}".format(diabetes_Normal_count, diabetes_Type1_count, diabetes_Type2_count))

X = newDataSet.iloc[:,:-1].values
y = newDataSet.iloc[:,6].values

from sklearn.impute import SimpleImputer
fill_values = SimpleImputer(missing_values= 0, strategy = 'mean')
X[:,1:6] = fill_values.fit_transform(X[:,1:6])

from sklearn.model_selection import train_test_split
X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, y, test_size = 0.1, random_state = 0)
from sklearn.preprocessing import StandardScaler
scale_X = StandardScaler()
X_train_new = scale_X.fit_transform(X_train_new)
X_test_new = scale_X.transform(X_test_new)

"""# SVM"""

from sklearn.svm import SVC
SVM_classifier = SVC(kernel = 'rbf', gamma = 'auto', random_state = 0)
SVM_classifier.fit(X_train_new, y_train_new)
SVM_y_pred_new = SVM_classifier.predict(X_test_new)

from sklearn.metrics import confusion_matrix, accuracy_score
cm_SVM_new = confusion_matrix(y_test_new, SVM_y_pred_new)
ac_SVM_new = accuracy_score(y_test_new, SVM_y_pred_new)
print("Confusion Matrix :")
print(cm_SVM_new)
print("SVM Train/test Split Accurary: ", ac_SVM_new)

"""# KNN"""

#KNN Classifier Algorithm
from sklearn.neighbors import KNeighborsClassifier
KNNClassifier_new = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)
KNNClassifier_new.fit(X_train_new, y_train_new)
KNN_y_pred_new = KNNClassifier.predict(X_test_new)

cm_KNNclass_new = confusion_matrix(y_test_new, KNN_y_pred_new)
ac_KNNclass_new = accuracy_score(y_test_new,KNN_y_pred_new)
print("Confusion Matrix :")
print(cm_KNNclass_new)
print("KNN Train/test Split Accurary: ", ac_KNNclass_new)

"""# Decision Tree"""

#Decision Tree Classifier Algorithm
from sklearn.tree import DecisionTreeClassifier
DTreeClassifier_new = DecisionTreeClassifier(criterion="entropy", random_state=0)
DTreeClassifier.fit(X_train_new, y_train_new)

DTree_y_pred_new = DTreeClassifier.predict(X_test_new)

cm_dTree_new = confusion_matrix(y_test_new, DTree_y_pred_new)
ac_dTree_new = accuracy_score(y_test_new,DTree_y_pred_new)
print("Confusion Matrix :")
print(cm_dTree_new)
print("KNN Train/test Split Accurary: ", ac_dTree_new)

"""# Logisitic Regression"""

from sklearn.linear_model import LogisticRegression
LogisticClassifier_new = LogisticRegression(random_state = 0)
LogisticClassifier.fit(X_train_new, y_train_new)

log_y_pred_new = LogisticClassifier.predict(X_test_new)

cm_log_new = confusion_matrix(y_test_new, log_y_pred_new)
ac_log_new = accuracy_score(y_test_new,log_y_pred_new)
print("Confusion Matrix :")
print(cm_log_new)
print("KNN Train/test Split Accurary: ", ac_log_new)

"""# Naive-Bayes"""

from sklearn.naive_bayes import GaussianNB
NBclassifier_new = GaussianNB()
NBclassifier.fit(X_train_new, y_train_new)

NB_y_pred_new = NBclassifier.predict(X_test_new)

cm_nb_new = confusion_matrix(y_test_new, NB_y_pred_new)
ac_nb_new = accuracy_score(y_test_new,NB_y_pred_new)
print("Confusion Matrix :")
print(cm_nb_new)
print("KNN Train/test Split Accurary: ", ac_nb_new)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
randomForestClassifier=RandomForestClassifier(n_estimators=100)
randomForestClassifier.fit(X_train,y_train)

randomForestClassifier.score(X_test_new,y_test_new)
rand_y_pred_new=randomForestClassifier.predict(X_test_new)
cm_randomForest_new= confusion_matrix(y_test_new,rand_y_pred_new)
ac_randomFores_new= accuracy_score(y_test_new,rand_y_pred_new)
print("Random Forest Classifier Accuracy:",ac_randomFores_new)
print("Random Forest Classifier Confusion Matrix",cm_randomForest_new)